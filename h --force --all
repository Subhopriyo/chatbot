[33mcommit 3e58713cc49bd8fc4cc3deb548e9bf53aa53a3a8[m
Author: Panbhuarasane A <panbhuofficial@gmail.com>
Date:   Sat Nov 1 18:54:52 2025 +0530

    first commit

[1mdiff --git a/backend/app.py b/backend/app.py[m
[1mnew file mode 100644[m
[1mindex 0000000..d8f0fab[m
[1m--- /dev/null[m
[1m+++ b/backend/app.py[m
[36m@@ -0,0 +1,950 @@[m
[32m+[m[32mfrom flask import Flask, request, jsonify, send_from_directory[m
[32m+[m[32mfrom flask_cors import CORS[m
[32m+[m[32mfrom langchain_community.vectorstores import Chroma[m
[32m+[m[32mfrom langchain_community.embeddings import HuggingFaceEmbeddings[m
[32m+[m[32mfrom langchain.text_splitter import RecursiveCharacterTextSplitter[m
[32m+[m[32mimport pandas as pd[m
[32m+[m[32mimport matplotlib.pyplot as plt[m
[32m+[m[32mimport numpy as np[m
[32m+[m[32mimport google.generativeai as genai[m
[32m+[m[32mimport os, uuid, warnings, shutil, re, json[m
[32m+[m[32mfrom werkzeug.utils import secure_filename[m
[32m+[m[32mfrom pptx import Presentation[m
[32m+[m[32mimport base64[m
[32m+[m[32mimport logging[m
[32m+[m[32mimport seaborn as sns[m
[32m+[m[32mimport requests[m
[32m+[m[32mfrom bs4 import BeautifulSoup[m
[32m+[m
[32m+[m[32m# Configure matplotlib for headless environment[m
[32m+[m[32mplt.switch_backend('Agg')[m
[32m+[m[32mplt.style.use('dark_background')[m
[32m+[m
[32m+[m[32m# Configure logging[m
[32m+[m[32mlogging.basicConfig(level=logging.INFO)[m
[32m+[m[32mlogger = logging.getLogger(__name__)[m
[32m+[m
[32m+[m[32m# Configuration[m
[32m+[m[32mGEMINI_API_KEY = os.getenv("GEMINI_API_KEY")[m
[32m+[m[32mif GEMINI_API_KEY:[m
[32m+[m[32m    genai.configure(api_key=GEMINI_API_KEY)[m
[32m+[m[32m    logger.info("âœ“ Gemini API configured")[m
[32m+[m[32melse:[m
[32m+[m[32m    warnings.warn("âš ï¸ GEMINI_API_KEY not set")[m
[32m+[m
[32m+[m[32m# Document Loaders[m
[32m+[m[32mLOADERS = {}[m
[32m+[m[32mtry:[m
[32m+[m[32m    from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader[m
[32m+[m[32m    LOADERS.update({'pdf': PyPDFLoader, 'txt': TextLoader, 'docx': Docx2txtLoader})[m
[32m+[m[32m    logger.info("âœ“ Document loaders loaded successfully")[m
[32m+[m[32mexcept ImportError as e:[m
[32m+[m[32m    logger.warning("âš ï¸ Limited loader support")[m
[32m+[m
[32m+[m[32m# Flask setup[m
[32m+[m[32mapp = Flask(__name__)[m
[32m+[m[32mCORS(app)[m
[32m+[m
[32m+[m[32m# Directories[m
[32m+[m[32mUPLOAD_FOLDER = os.path.join(os.path.dirname(__file__), 'uploads')[m
[32m+[m[32mPLOTS_FOLDER = os.path.join(os.path.dirname(__file__), 'static', 'plots')[m
[32m+[m[32mVECTOR_DB_DIR = os.path.join(os.path.dirname(__file__), 'db_miniLM')[m
[32m+[m
[32m+[m[32m# Ensure directories exist[m
[32m+[m[32mos.makedirs(UPLOAD_FOLDER, exist_ok=True)[m
[32m+[m[32mos.makedirs(PLOTS_FOLDER, exist_ok=True)[m
[32m+[m[32mos.makedirs(os.path.dirname(PLOTS_FOLDER), exist_ok=True)  # Ensure static folder exists[m
[32m+[m
[32m+[m[32m# Constants[m
[32m+[m[32mEMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"[m
[32m+[m[32mALLOWED_EXTENSIONS = {'txt', 'pdf', 'docx', 'pptx', 'ppt', 'xlsx', 'xls', 'csv'}[m
[32m+[m[32mexcel_data_store = {}[m
[32m+[m
[32m+[m[32m# Keywords[m
[32m+[m[32mGRAPH_KEYWORDS = ['graph', 'chart', 'plot', 'visualize', 'visualization', 'bar', 'line', 'pie', 'scatter', 'histogram', 'show', 'draw', 'create chart'][m
[32m+[m[32mDOCUMENT_KEYWORDS = ['summarise', 'summarize', 'summary', 'document', 'content', 'explain', 'analyze', 'findings'][m
[32m+[m
[32m+[m[32m# Helper Functions[m
[32m+[m[32mdef allowed_file(filename):[m
[32m+[m[32m    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS[m
[32m+[m
[32m+[m[32mdef clear_vector_database():[m
[32m+[m[32m    try:[m
[32m+[m[32m        if os.path.exists(VECTOR_DB_DIR):[m
[32m+[m[32m            shutil.rmtree(VECTOR_DB_DIR)[m
[32m+[m[32m            logger.info("ðŸ—‘ï¸ Cleared vector database")[m
[32m+[m[32m            return True[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        logger.error(f"âš ï¸ Could not clear vector database: {str(e)}")[m
[32m+[m[32m        return False[m
[32m+[m[32m    return True[m
[32m+[m
[32m+[m[32mdef has_documents():[m
[32m+[m[32m    try:[m
[32m+[m[32m        return os.path.exists(VECTOR_DB_DIR) and len(Chroma(persist_directory=VECTOR_DB_DIR, embedding_function=HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)).similarity_search("test", k=1)) > 0[m
[32m+[m[32m    except:[m
[32m+[m[32m        return False[m
[32m+[m
[32m+[m[32mdef has_data():[m
[32m+[m[32m    return len(excel_data_store) > 0[m
[32m+[m
[32m+[m[32mdef is_graph_request(question):[m
[32m+[m[32m    return any(keyword in question.lower() for keyword in GRAPH_KEYWORDS)[m
[32m+[m
[32m+[m[32mdef is_document_specific_question(question):[m
[32m+[m[32m    return any(keyword in question.lower() for keyword in DOCUMENT_KEYWORDS)[m
[32m+[m
[32m+[m[32mdef search_web(query, max_results=3):[m
[32m+[m[32m    """Simple web search using DuckDuckGo (you can replace with your preferred search API)"""[m
[32m+[m[32m    try:[m
[32m+[m[32m        # This is a simple implementation - replace with your preferred search API[m
[32m+[m[32m        search_url = f"https://duckduckgo.com/html/?q={query}"[m
[32m+[m[32m        headers = {[m
[32m+[m[32m            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'[m
[32m+[m[32m        }[m
[32m+[m[41m        [m
[32m+[m[32m        response = requests.get(search_url, headers=headers, timeout=10)[m
[32m+[m[32m        soup = BeautifulSoup(response.content, 'html.parser')[m
[32m+[m[41m        [m
[32m+[m[32m        results = [][m
[32m+[m[32m        result_links = soup.find_all('a', class_='result__a')[:max_results][m
[32m+[m[41m        [m
[32m+[m[32m        for link in result_links:[m
[32m+[m[32m            title = link.get_text()[m
[32m+[m[32m            url = link.get('href')[m
[32m+[m[32m            if url and title:[m
[32m+[m[32m                results.append({'title': title, 'url': url})[m
[32m+[m[41m        [m
[32m+[m[32m        return results[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        logger.error(f"Web search error: {str(e)}")[m
[32m+[m[32m        return [][m
[32m+[m
[32m+[m[32mdef ask_gemini(prompt, temp=0.7, include_web_context=False, web_query=None):[m
[32m+[m[32m    if not GEMINI_API_KEY:[m
[32m+[m[32m        return "âš ï¸ Gemini API key not set"[m
[32m+[m[41m    [m
[32m+[m[32m    try:[m
[32m+[m[32m        model = genai.GenerativeModel("gemini-1.5-flash")[m
[32m+[m[41m        [m
[32m+[m[32m        # If web search is requested, add web context[m
[32m+[m[32m        if include_web_context and web_query:[m
[32m+[m[32m            web_results = search_web(web_query)[m
[32m+[m[32m            if web_results:[m
[32m+[m[32m                web_context = "Here are some relevant web search results:\n"[m
[32m+[m[32m                for i, result in enumerate(web_results, 1):[m
[32m+[m[32m                    web_context += f"{i}. {result['title']} - {result['url']}\n"[m
[32m+[m[41m                [m
[32m+[m[32m                prompt = f"{web_context}\n\nBased on current information and the above sources, {prompt}"[m
[32m+[m[41m        [m
[32m+[m[32m        response = model.generate_content(prompt, generation_config=genai.types.GenerationConfig(max_output_tokens=2000, temperature=temp))[m
[32m+[m[32m        return response.text.strip() if response.text else "No response generated"[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        logger.error(f"Gemini API error: {str(e)}")[m
[32m+[m[32m        return f"Error: {str(e)}"[m
[32m+[m
[32m+[m[32mdef extract_ppt_content(filepath):[m
[32m+[m[32m    """Extract PowerPoint content using python-pptx and Gemini for analysis"""[m
[32m+[m[32m    try:[m
[32m+[m[32m        if not os.path.exists(filepath):[m
[32m+[m[32m            return f"Error: File not found at {filepath}"[m
[32m+[m[41m        [m
[32m+[m[32m        file_size = os.path.getsize(filepath)[m
[32m+[m[32m        if file_size > 50 * 1024 * 1024:  # 50MB limit[m
[32m+[m[32m            return "Error: File too large (>50MB)"[m
[32m+[m[41m        [m
[32m+[m[32m        logger.info(f"ðŸ“„ Processing PowerPoint file: {filepath} ({file_size} bytes)")[m
[32m+[m[41m        [m
[32m+[m[32m        try:[m
[32m+[m[32m            prs = Presentation(filepath)[m
[32m+[m[32m        except Exception as e:[m
[32m+[m[32m            return f"Error: Unable to open PowerPoint file - {str(e)}"[m
[32m+[m[41m        [m
[32m+[m[32m        slides_content = [][m
[32m+[m[41m        [m
[32m+[m[32m        for i, slide in enumerate(prs.slides):[m
[32m+[m[32m            slide_text = [][m
[32m+[m[32m            slide_text.append(f"--- Slide {i+1} ---")[m
[32m+[m[41m            [m
[32m+[m[32m            text_found = False[m
[32m+[m[32m            for shape in slide.shapes:[m
[32m+[m[32m                try:[m
[32m+[m[32m                    if hasattr(shape, "text") and shape.text.strip():[m
[32m+[m[32m                        slide_text.append(shape.text.strip())[m
[32m+[m[32m                        text_found = True[m
[32m+[m[41m                    [m
[32m+[m[32m                    if hasattr(shape, "table"):[m
[32m+[m[32m                        table_text = [][m
[32m+[m[32m                        for row in shape.table.rows:[m
[32m+[m[32m                            row_text = [][m
[32m+[m[32m                            for cell in row.cells:[m
[32m+[m[32m                                if cell.text.strip():[m
[32m+[m[32m                                    row_text.append(cell.text.strip())[m
[32m+[m[32m                            if row_text:[m
[32m+[m[32m                                table_text.append(" | ".join(row_text))[m
[32m+[m[32m                        if table_text:[m
[32m+[m[32m                            slide_text.extend(table_text)[m
[32m+[m[32m                            text_found = True[m
[32m+[m[41m                            [m
[32m+[m[32m                except Exception as e:[m
[32m+[m[32m                    logger.warning(f"Error processing shape on slide {i+1}: {str(e)}")[m
[32m+[m[32m                    continue[m
[32m+[m[41m            [m
[32m+[m[32m            if not text_found:[m
[32m+[m[32m                slide_text.append("[No text content found in this slide]")[m
[32m+[m[41m                [m
[32m+[m[32m            slides_content.append("\n".join(slide_text))[m
[32m+[m[41m        [m
[32m+[m[32m        if not slides_content:[m
[32m+[m[32m            return "Error: No slides found in PowerPoint file"[m
[32m+[m[41m        [m
[32m+[m[32m        full_content = "\n\n".join(slides_content)[m
[32m+[m[41m        [m
[32m+[m[32m        gemini_prompt = f"""Please analyze and structure this PowerPoint content:[m
[32m+[m
[32m+[m[32m{full_content}[m
[32m+[m
[32m+[m[32mProvide a well-structured summary that:[m
[32m+[m[32m1. Identifies key topics and themes[m
[32m+[m[32m2. Organizes information logically[m
[32m+[m[32m3. Highlights important facts, statistics, and findings[m
[32m+[m[32m4. Makes the content searchable and useful for Q&A[m
[32m+[m[32m5. Preserves important numerical data and scientific facts[m
[32m+[m
[32m+[m[32mFormat as clear, coherent text suitable for document analysis and retrieval."""[m
[32m+[m[41m        [m
[32m+[m[32m        enhanced_content = ask_gemini(gemini_prompt, temp=0.3)[m
[32m+[m[41m        [m
[32m+[m[32m        if enhanced_content and "Error:" not in enhanced_content:[m
[32m+[m[32m            logger.info("âœ“ PowerPoint content enhanced with Gemini")[m
[32m+[m[32m            return enhanced_content[m
[32m+[m[32m        else:[m
[32m+[m[32m            logger.warning("âš ï¸ Gemini enhancement failed, using raw content")[m
[32m+[m[32m            return full_content[m
[32m+[m[41m        [m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        logger.error(f"Error extracting PowerPoint content: {str(e)}")[m
[32m+[m[32m        return f"Error extracting PowerPoint content: {str(e)}"[m
[32m+[m
[32m+[m[32mdef process_document(filepath, filename):[m
[32m+[m[32m    ext = filename.rsplit('.', 1)[1].lower()[m
[32m+[m[41m    [m
[32m+[m[32m    try:[m
[32m+[m[32m        if ext in ['pptx', 'ppt']:[m
[32m+[m[32m            content = extract_ppt_content(filepath)[m
[32m+[m[32m            if content.startswith("Error"):[m
[32m+[m[32m                return None, content[m
[32m+[m[41m            [m
[32m+[m[32m            from langchain.schema import Document[m
[32m+[m[41m            [m
[32m+[m[32m            chunks = [][m
[32m+[m[32m            sections = content.split('--- Slide')[m
[32m+[m[32m            for i, section in enumerate(sections):[m
[32m+[m[32m                if section.strip():[m
[32m+[m[32m                    if i > 0:[m
[32m+[m[32m                        section = '--- Slide' + section[m
[32m+[m[41m                    [m
[32m+[m[32m                    if len(section) > 2000:[m
[32m+[m[32m                        sub_chunks = section.split('\n\n')[m
[32m+[m[32m                        for j, sub_chunk in enumerate(sub_chunks):[m
[32m+[m[32m                            if sub_chunk.strip():[m
[32m+[m[32m                                chunks.append(sub_chunk.strip())[m
[32m+[m[32m                    else:[m
[32m+[m[32m                        chunks.append(section.strip())[m
[32m+[m[41m            [m
[32m+[m[32m            pages = [][m
[32m+[m[32m            for i, chunk in enumerate(chunks):[m
[32m+[m[32m                if chunk.strip():[m
[32m+[m[32m                    doc = Document([m
[32m+[m[32m                        page_content=chunk.strip(),[m
[32m+[m[32m                        metadata={[m
[32m+[m[32m                            "page": i + 1,[m[41m [m
[32m+[m[32m                            "source": filename,[m[41m [m
[32m+[m[32m                            "type": "presentation",[m[41m [m
[32m+[m[32m                            "file_type": ext,[m
[32m+[m[32m                            "chunk_id": i[m
[32m+[m[32m                        }[m
[32m+[m[32m                    )[m
[32m+[m[32m                    pages.append(doc)[m
[32m+[m[41m            [m
[32m+[m[32m            logger.info(f"âœ“ PowerPoint processed: {len(pages)} chunks created")[m
[32m+[m[32m            return pages, None[m
[32m+[m[41m            [m
[32m+[m[32m        elif ext in LOADERS:[m
[32m+[m[32m            loader = LOADERS[ext](filepath, encoding='utf-8') if ext == 'txt' else LOADERS[ext](filepath)[m
[32m+[m[32m            pages = loader.load()[m
[32m+[m[32m            if not pages:[m
[32m+[m[32m                return None, "No content extracted from document"[m
[32m+[m[41m            [m
[32m+[m[32m            for i, doc in enumerate(pages):[m
[32m+[m[32m                doc.metadata = {"page": i + 1, "source": filename, "type": "document", "file_type": ext}[m
[32m+[m[32m            return pages, None[m
[32m+[m[32m        else:[m
[32m+[m[32m            return None, f"Unsupported format: {ext}"[m
[32m+[m[41m            [m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        logger.error(f"Error processing {filename}: {str(e)}")[m
[32m+[m[32m        return None, f"Error processing {filename}: {str(e)}"[m
[32m+[m
[32m+[m[32mdef get_document_context(question, k=5):[m
[32m+[m[32m    try:[m
[32m+[m[32m        db = Chroma(persist_directory=VECTOR_DB_DIR, embedding_fun